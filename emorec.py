# -*- coding: utf-8 -*-
"""EmoRec.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RMDo-U1wSIEj3tUkGpH_co8P52345fyc
"""

import numpy as np
import argparse
import matplotlib.pyplot as plt
import cv2
import tensorflow as tf
from tensorflow import keras
from keras.utils import to_categorical
import os

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')
tf.config.experimental_connect_to_cluster(resolver)
# This is the TPU initialization code that has to be at the beginning.
tf.tpu.experimental.initialize_tpu_system(resolver)
print("All devices: ", tf.config.list_logical_devices('TPU'))

X_train = np.load('/content/drive/MyDrive/COMP 4026 Project/data/X_train.npy')
y_train = np.load('/content/drive/MyDrive/COMP 4026 Project/data/y_train.npy')
X_test = np.load('/content/drive/MyDrive/COMP 4026 Project/data/X_test.npy')
y_test = np.load('/content/drive/MyDrive/COMP 4026 Project/data/y_test.npy')

X_train.shape,y_train.shape,X_test.shape,y_test.shape

y_test = np.load('/content/drive/MyDrive/COMP 4026 Project/data/y_test.npy')

plt.imshow(X_train[20],cmap='gray')

y_train[20]

X_train = np.expand_dims(X_train,-1)
X_test = np.expand_dims(X_test,-1)

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

X_train.shape,X_test.shape,y_train.shape,y_test.shape

X_train.shape,X_test.shape,y_train.shape,y_test.shape

def getModel(INPUT_SHAPE = (48,48,1)):

    inp = keras.layers.Input(shape=INPUT_SHAPE)

    conv1 = keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding='same')(inp)  
    pool1 = keras.layers.MaxPooling2D(pool_size=2)(conv1)
    norm1 = keras.layers.BatchNormalization()(pool1)
    drop1 = keras.layers.Dropout(0.4)(norm1)

    conv2 = keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same')(drop1)
    pool2 = keras.layers.MaxPooling2D(pool_size=2)(conv2)
    norm2 = keras.layers.BatchNormalization()(pool2)
    drop2 = keras.layers.Dropout(0.4)(norm2)

    conv3 = keras.layers.Conv2D(128, kernel_size=3,activation='relu', padding='same')(drop2)
    pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)
    norm3 = keras.layers.BatchNormalization()(pool3)
    drop3 = keras.layers.Dropout(0.4)(norm3)

    conv4 = keras.layers.Conv2D(256, kernel_size=3,activation='relu', padding='same')(drop3)
    pool4 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4)
    norm4 = keras.layers.BatchNormalization()(pool4)
    drop4 = keras.layers.Dropout(0.4)(norm4)

    conv5 = keras.layers.Conv2D(512, kernel_size=3,activation='relu', padding='same')(drop4)
    pool5 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv5)
    norm5 = keras.layers.BatchNormalization()(pool5)
    drop5 = keras.layers.Dropout(0.4)(norm5)

    flat = keras.layers.Flatten()(drop5)  #Flatten the matrix to get it ready for dense.
    #flat = keras.layers.GlobalAveragePooling2D()(drop4)

    hidden1 = keras.layers.Dense(1024, activation='relu')(flat)
    drop4 = keras.layers.Dropout(0.4)(hidden1)

    out = keras.layers.Dense(7, activation='softmax')(drop4)   

    model = keras.Model(inputs=inp, outputs=out)

    return model

model = getModel()

initial_learning_rate = 0.001
lr_schedule = keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True
)


checkpointer_ = keras.callbacks.ModelCheckpoint("2D_EmoClass_c3.h5", monitor='val_loss',save_best_only=True)
model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),
              loss='categorical_crossentropy',metrics=['accuracy'])

model.summary()

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

X_train.shape

with tf.device('/device:GPU:0'):

  hist_1 = model.fit(
            X_train,
            y_train,
            batch_size=32,
            epochs=100,
            class_weight = {0:0.9,1:12,2:1,3:0.7,4:0.9,5:2,6:0.9},
            shuffle=True,
            verbose=2,
            validation_split=0.2,
            #validation_data=(X_val,y_val),
            callbacks=[checkpointer_],
        )

model.load_weights('/content/2D_EmoClass_c3.h5')

loss, accuracy = model.evaluate(X_test, y_test, verbose=0,batch_size=32)
loss, accuracy

y_test = np.load('/content/drive/MyDrive/COMP 4026 Project/data/y_test.npy')
y_test.shape

from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix,accuracy_score,ConfusionMatrixDisplay
from sklearn.metrics import classification_report

y_pred1 = model.predict(X_test,batch_size=32)
y_pred = np.argmax(y_pred1, axis=1)
#y_pred_ = to_categorical(y_pred)

ConfusionMatrixDisplay(confusion_matrix(y_test,y_pred),display_labels=[0,1,2,3,4,5,6],).plot()

print(classification_report(y_test,y_pred))
print(accuracy_score(y_test,y_pred))
print(precision_score(y_test,y_pred,average='macro'))
print(recall_score(y_test,y_pred,average='macro'))
print(f1_score(y_test,y_pred,average='macro'))

print(confusion_matrix(y_test,y_pred))

f, (ax1, ax2,) = plt.subplots(1, 2, figsize=(20, 4),)
t = f.suptitle('2D Emotion Classification Performance', fontsize=12)
f.subplots_adjust(top=0.85, wspace=0.3)

max_epoch = len(hist_1.history['accuracy'])+1
epoch_list = list(range(1,max_epoch))

ax1.plot(epoch_list, hist_1.history['accuracy'], label='Train Accuracy')
ax1.plot(epoch_list, hist_1.history['val_accuracy'], label='Validation Accuracy')
ax1.set_xticks(np.arange(1, max_epoch, 5))
ax1.set_ylabel('Accuracy Value')
ax1.set_xlabel('Epoch')
ax1.set_title('Accuracy')
l1 = ax1.legend(loc="best")

ax2.plot(epoch_list, hist_1.history['loss'], label='Train Loss')
ax2.plot(epoch_list, hist_1.history['val_loss'], label='Validation Loss')
ax2.set_xticks(np.arange(1, max_epoch, 5))
ax2.set_ylabel('Loss Value')
ax2.set_xlabel('Epoch')
ax2.set_title('Loss')
l2 = ax2.legend(loc="best")

